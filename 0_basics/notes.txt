MACHINE LEARNING: Ability of computers to learn without being explicitly programmed. A computer
learns when its performance to some task improves with experience; Good if existing solution
requires a lot of fine tuning, complex problems where known algorithm are not sufficient, if
algorithm needs to adapt to changes and to get insight into data (DATA MINING);


TYPES OF ML:
- Supervised vs Unsupervised
  - Supervised: training's set includes desired solution (LABELS);
  - Unsupervised: unlabeled data;
  - Semi-supervised: Combine supervised and unsupervised learning;
  - Reinforcement: The agent observes the environment, preforms actions and gets rewards. It
    then develops a policy to get the most rewards over time;

- Batch vs Online
  Does the system learn incremental from stream of data coming in or not?
  - Batch
    Incapable of learning incrementally; Needs all available data on training;
    # Offline learning  // can be automated
  - Online Learning
    Learns incremental by taking in training instances or mini-batches over time; Learns on the
    fly; Once trained, it can forget the data and focus on new ones; 
    # Out-of-core: Splits data into processable chunks, learns, then continuous to the next chunk;
    # Learning rate: Speed vs stability;

- Instance vs Model
  How does the system generalize?
  - Instance based
    Learn examples by heart and categorize new instances by similarity to known ones;
  - Model based
    System builds a model of data to make prediction;  


CHALLENGES:
- Insufficient quantity data  # Unreasonable effectiveness of data
- Nonrepresentative Training Data
  - Training set needs to be cases that shall be generalized
  - Sample noise (non-representative data as a result of chance)
  - Sample bias (Sampling method is flawed)
- Poor quality
- Irrelevant features # Feature engineering
  - feature selection
  - feature extraction
  - new data
- Over-fitting
  happens when model is to complex relative to the data;
  - Regularization: Constrain a model to make it simpler to reduce risk of over-fitting. i.e.
    regulate degree of freedom.
- Under-fitting
  Algorithm to simple to catch complexity;

TESTING AND VALIDATION
- Split data
  - Test-Set
    Use to estimate generalization error => how well does the training set perform on unknown data?
  - Training-Set
    Used to train data

- Hyper parameter Tuning and model selection
  Avoid fitting hypermarket or model to specific training data set.
  - Holdout set or validation set or dev set
  Hold out part of training set - train model on this - select the best one - test on whole test
  set.
  - Repeated cross validation
  Train on several holdout sets - average out the results to get an estimate of the model
  performance.

Data mismatch
Training data do not represent production data properly 
    
      

Training set, Training instance (sample), training data (with respect to task), accuracy,
classification, predictors, regression, attribute (is a data type), features (attribute + value),
logistic regression, feature extraction (combining features into one; possible if strong
correlation), similarity, noise (partly random), model selection, model parameter, performance
measure: Utility function or cost function, training (fit model to data), hyper parameter
(Parameter of the ML-Alg. not the model),

