{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f02e26-79b1-4976-8e89-2ab0a4855a33",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5547fe-65c4-45f1-b847-5fbaebcfa47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebce5514-ab0f-4a60-b980-b5ddcfc0bd65",
   "metadata": {},
   "source": [
    "# Perception\n",
    "\n",
    "Simplest NN architecture. Based on TLU where a TLU component computes it's value as the wighted sum of input nodes, a linear combination of inputs.\n",
    "Preception in made up by a layer of TLUs with each TLU connectd to all inputs (dense layer). \n",
    "\n",
    "h_W,B = phi(XW + b) where: X = Matrix input vectors, Q = weight matrix, b = bias vector.  phi = activation function.\n",
    "\n",
    "Training via Hebb's rule: For each output neuron that produces a wrong prediction, it reinforces the weights of inputs that would have contributed to the right outcome.\n",
    "\n",
    "Decision boundaries are linear; If training instances are linearly speratable they can converge so a solution (Preception convergence theorem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d33fb99-ac94-431c-8658-aa3542862338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int)\n",
    "\n",
    "per_clf = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d509eb-4afb-497a-9566-35f4a8d5874b",
   "metadata": {},
   "source": [
    "# Multi layer percetption\n",
    "\n",
    "Several \"hidden\" TLU layers. Problem was to train them. Solution: Backpropagation (It is gradient decent with an efficient technique to compute the gradients automatically)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b5fce2-1205-41b8-b442-149370976281",
   "metadata": {},
   "source": [
    "**Backpropagation: reverse-mode autofidd**\n",
    "\n",
    "1. Handels mini batches at a time and iterates several time over the whole set (One iterration is called an epoch).\n",
    "\n",
    "2. Forword pass: Batch is passd to input layer - compute next layer - pass it't results to the next later - ...repeat - outputlayer -> Like a prediction but we store ther intermediate results.\n",
    "\n",
    "3. Measure output error (i.e. loss function).\n",
    "\n",
    "4. Compute how much each output connection contributs to the error (done analytically by applying the chain rule).\n",
    "\n",
    "5. Mesure how much of these error contributions came from the layer below - working backwards through the model until reaching input layer - propagating the error gradient backwards! \n",
    "\n",
    "6. Tweak connections weights using error gradients.\n",
    "\n",
    "Initial values need to be random. I.e. if all nodes=0 then all would contribute equally to the error and be tweaked equally as well. The mode would act as if there is only one node. \n",
    "\n",
    "To make it work, the archiceture is changed: The activation function to a contiouse function (that can represent a gradient != step function which can't). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cbb5c3c-3904-4c85-a0e5-c8e515409bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f25ff-dc84-4d18-ad05-df5e63830d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "komodoenv2021Nov",
   "language": "python",
   "name": "komodoenv2021nov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
